{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO88qRDqHZsZfca4zZr8Ijq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushkar0655g/Generative-AI/blob/main/MULTI_40enhanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q yt-dlp\n",
        "!pip install -q transformers\n",
        "!apt-get install -y ffmpeg -qq\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.colab import files\n",
        "import whisper\n",
        "import subprocess\n",
        "import os\n",
        "from transformers import MarianMTModel, MarianTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Define default video path\n",
        "video_path = \"/content/video.mp4\"\n",
        "\n",
        "# Function to download video from YouTube\n",
        "def download_youtube_video(url, output_path):\n",
        "    cookies_path = \"/content/cookies.txt\"\n",
        "    use_cookies = False\n",
        "\n",
        "    print(\"If the video requires sign-in (e.g., age-restricted), upload a cookies file (optional).\")\n",
        "    print(\"Guide: https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp\")\n",
        "    uploaded = files.upload()\n",
        "    if \"cookies.txt\" in uploaded:\n",
        "        with open(cookies_path, \"wb\") as f:\n",
        "            f.write(uploaded[\"cookies.txt\"])\n",
        "        use_cookies = True\n",
        "        print(\"Cookies uploaded successfully.\")\n",
        "\n",
        "    try:\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--user-agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "            \"-o\", output_path,\n",
        "        ]\n",
        "        if use_cookies:\n",
        "            command.extend([\"--cookies\", cookies_path])\n",
        "        command.append(url)\n",
        "\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        print(f\"Downloaded video to {output_path}\")\n",
        "        if use_cookies and os.path.exists(cookies_path):\n",
        "            os.remove(cookies_path)\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to download video from {url}:\")\n",
        "        print(f\"Error output: {e.stderr}\")\n",
        "        if \"Sign in to confirm you’re not a bot\" in e.stderr or \"age-restricted\" in e.stderr:\n",
        "            print(\"\\n⚠️ This video requires authentication (e.g., sign-in or age verification).\")\n",
        "            if not use_cookies:\n",
        "                print(\"You didn’t upload cookies. Options:\")\n",
        "                print(\"1. Upload a cookies.txt file (restart and try again).\")\n",
        "                print(\"   Export cookies: https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies\")\n",
        "                print(\"2. Try a different public video.\")\n",
        "                print(\"3. Download locally with yt-dlp and upload to Colab.\")\n",
        "                print(\"   Command: yt-dlp <URL> -o video.mp4\")\n",
        "            else:\n",
        "                print(\"Cookies provided but still failed. Ensure they’re valid and from a signed-in browser.\")\n",
        "        else:\n",
        "            print(\"Unexpected error. Check the URL or try again.\")\n",
        "        if use_cookies and os.path.exists(cookies_path):\n",
        "            os.remove(cookies_path)\n",
        "        return False\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Function to create an SRT file\n",
        "def create_srt(segments, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, segment in enumerate(segments, 1):\n",
        "            start = f\"{segment['start']:.3f}\".replace(\".\", \",\")\n",
        "            end = f\"{segment['end']:.3f}\".replace(\".\", \",\")\n",
        "            text = segment[\"text\"].strip()\n",
        "            f.write(f\"{i}\\n00:00:{start} --> 00:00:{end}\\n{text}\\n\\n\")\n",
        "    print(f\"Subtitles saved to {filename}\")\n",
        "\n",
        "# Function to process video and generate subtitles\n",
        "def process_video(video_path, language):\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Error: Video file {video_path} does not exist.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        print(\"Transcribing video to English...\")\n",
        "        result = model.transcribe(video_path, language=\"en\")\n",
        "\n",
        "        if language == \"english\":\n",
        "            segments = result[\"segments\"]\n",
        "        elif language == \"telugu\":\n",
        "            model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            translation_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "            tgt_lang = \"tel_Telu\"\n",
        "            segments = []\n",
        "            print(\"Translating to Telugu using NLLB-200 Distilled...\")\n",
        "            for segment in result[\"segments\"]:\n",
        "                inputs = tokenizer(segment[\"text\"], return_tensors=\"pt\", padding=True)\n",
        "                translated_tokens = translation_model.generate(**inputs, forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang))\n",
        "                translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "                segment[\"text\"] = translated_text\n",
        "                segments.append(segment)\n",
        "        else:\n",
        "            if language == \"hindi\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "            elif language == \"spanish\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
        "            elif language == \"french\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "            elif language == \"german\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "            else:\n",
        "                print(f\"Language '{language}' not supported.\")\n",
        "                return None\n",
        "\n",
        "            tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "            translation_model = MarianMTModel.from_pretrained(model_name)\n",
        "            segments = []\n",
        "            print(f\"Translating to {language}...\")\n",
        "            for segment in result[\"segments\"]:\n",
        "                inputs = tokenizer(segment[\"text\"], return_tensors=\"pt\", padding=True)\n",
        "                translated = translation_model.generate(**inputs)\n",
        "                translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "                segment[\"text\"] = translated_text\n",
        "                segments.append(segment)\n",
        "\n",
        "        srt_path = f\"/content/subtitles_{language}.srt\"\n",
        "        create_srt(segments, srt_path)\n",
        "        return srt_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing video: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    print(\"Choose the source of the video:\")\n",
        "    print(\"1. YouTube\")\n",
        "    print(\"2. Local Drive Path (e.g., /content/video.mp4)\")\n",
        "    choice = input(\"Enter your choice (1 or 2): \").strip()\n",
        "\n",
        "    if os.path.exists(video_path):\n",
        "        os.remove(video_path)  # Clean up previous file if it’s the default path\n",
        "\n",
        "    if choice == \"1\":\n",
        "        youtube_link = input(\"Enter the YouTube video URL: \").strip()\n",
        "        if not youtube_link:\n",
        "            print(\"Error: YouTube URL cannot be empty.\")\n",
        "            return\n",
        "        success = download_youtube_video(youtube_link, video_path)\n",
        "        if not success:\n",
        "            print(\"Failed to download YouTube video. Review the error above for next steps.\")\n",
        "            return\n",
        "        final_video_path = video_path  # Use the downloaded file\n",
        "    elif choice == \"2\":\n",
        "        drive_path = input(\"Enter the local drive path (e.g., /content/M4 Macbook Air Review_ Too Easy!.mkv): \").strip()\n",
        "        if not drive_path:\n",
        "            print(\"Error: Drive path cannot be empty.\")\n",
        "            return\n",
        "        if not os.path.exists(drive_path):\n",
        "            print(f\"Error: File not found at {drive_path}. Please upload the file to Colab first.\")\n",
        "            print(\"To upload: Use the Files tab on the left, or run 'from google.colab import files; files.upload()'.\")\n",
        "            return\n",
        "        final_video_path = drive_path  # Use the provided path directly\n",
        "    else:\n",
        "        print(\"Invalid choice.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nChoose the language for subtitles:\")\n",
        "    print(\"1. English\")\n",
        "    print(\"2. Hindi\")\n",
        "    print(\"3. Spanish\")\n",
        "    print(\"4. French\")\n",
        "    print(\"5. German\")\n",
        "    print(\"6. Telugu\")\n",
        "    language_choice = input(\"Enter your choice (1, 2, 3, 4, 5, or 6): \").strip()\n",
        "\n",
        "    language_map = {\n",
        "        \"1\": \"english\",\n",
        "        \"2\": \"hindi\",\n",
        "        \"3\": \"spanish\",\n",
        "        \"4\": \"french\",\n",
        "        \"5\": \"german\",\n",
        "        \"6\": \"telugu\"\n",
        "    }\n",
        "\n",
        "    if language_choice not in language_map:\n",
        "        print(\"Invalid choice.\")\n",
        "        return\n",
        "\n",
        "    language = language_map[language_choice]\n",
        "    print(f\"\\nStarting video processing for {language} subtitles...\")\n",
        "    srt_path = process_video(final_video_path, language)\n",
        "\n",
        "    if srt_path:\n",
        "        print(f\"\\nSample of {language} subtitles:\")\n",
        "        with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            print(f.read(500))\n",
        "        files.download(srt_path)\n",
        "    else:\n",
        "        print(\"Video failed to process. Please try again.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9_JNA_4OhA_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}