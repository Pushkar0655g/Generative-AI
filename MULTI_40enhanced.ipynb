{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO88qRDqHZsZfca4zZr8Ijq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushkar0655g/Generative-AI/blob/main/MULTI_40enhanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q yt-dlp\n",
        "!pip install -q transformers\n",
        "!apt-get install -y ffmpeg -qq\n",
        "\n",
        "# Import necessary libraries\n",
        "from google.colab import files\n",
        "import whisper\n",
        "import subprocess\n",
        "import os\n",
        "from transformers import MarianMTModel, MarianTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Define default video path\n",
        "video_path = \"/content/video.mp4\"\n",
        "\n",
        "# Function to download video from YouTube\n",
        "def download_youtube_video(url, output_path):\n",
        "    cookies_path = \"/content/cookies.txt\"\n",
        "    use_cookies = False\n",
        "\n",
        "    print(\"If the video requires sign-in (e.g., age-restricted), upload a cookies file (optional).\")\n",
        "    print(\"Guide: https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp\")\n",
        "    uploaded = files.upload()\n",
        "    if \"cookies.txt\" in uploaded:\n",
        "        with open(cookies_path, \"wb\") as f:\n",
        "            f.write(uploaded[\"cookies.txt\"])\n",
        "        use_cookies = True\n",
        "        print(\"Cookies uploaded successfully.\")\n",
        "\n",
        "    try:\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--user-agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "            \"-o\", output_path,\n",
        "        ]\n",
        "        if use_cookies:\n",
        "            command.extend([\"--cookies\", cookies_path])\n",
        "        command.append(url)\n",
        "\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        print(f\"Downloaded video to {output_path}\")\n",
        "        if use_cookies and os.path.exists(cookies_path):\n",
        "            os.remove(cookies_path)\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to download video from {url}:\")\n",
        "        print(f\"Error output: {e.stderr}\")\n",
        "        if \"Sign in to confirm you’re not a bot\" in e.stderr or \"age-restricted\" in e.stderr:\n",
        "            print(\"\\n⚠️ This video requires authentication (e.g., sign-in or age verification).\")\n",
        "            if not use_cookies:\n",
        "                print(\"You didn’t upload cookies. Options:\")\n",
        "                print(\"1. Upload a cookies.txt file (restart and try again).\")\n",
        "                print(\"   Export cookies: https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies\")\n",
        "                print(\"2. Try a different public video.\")\n",
        "                print(\"3. Download locally with yt-dlp and upload to Colab.\")\n",
        "                print(\"   Command: yt-dlp <URL> -o video.mp4\")\n",
        "            else:\n",
        "                print(\"Cookies provided but still failed. Ensure they’re valid and from a signed-in browser.\")\n",
        "        else:\n",
        "            print(\"Unexpected error. Check the URL or try again.\")\n",
        "        if use_cookies and os.path.exists(cookies_path):\n",
        "            os.remove(cookies_path)\n",
        "        return False\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Function to create an SRT file\n",
        "def create_srt(segments, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, segment in enumerate(segments, 1):\n",
        "            start = f\"{segment['start']:.3f}\".replace(\".\", \",\")\n",
        "            end = f\"{segment['end']:.3f}\".replace(\".\", \",\")\n",
        "            text = segment[\"text\"].strip()\n",
        "            f.write(f\"{i}\\n00:00:{start} --> 00:00:{end}\\n{text}\\n\\n\")\n",
        "    print(f\"Subtitles saved to {filename}\")\n",
        "\n",
        "# Function to process video and generate subtitles\n",
        "def process_video(video_path, language):\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Error: Video file {video_path} does not exist.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        print(\"Transcribing video to English...\")\n",
        "        result = model.transcribe(video_path, language=\"en\")\n",
        "\n",
        "        if language == \"english\":\n",
        "            segments = result[\"segments\"]\n",
        "        elif language == \"telugu\":\n",
        "            model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            translation_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "            tgt_lang = \"tel_Telu\"\n",
        "            segments = []\n",
        "            print(\"Translating to Telugu using NLLB-200 Distilled...\")\n",
        "            for segment in result[\"segments\"]:\n",
        "                inputs = tokenizer(segment[\"text\"], return_tensors=\"pt\", padding=True)\n",
        "                translated_tokens = translation_model.generate(**inputs, forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang))\n",
        "                translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "                segment[\"text\"] = translated_text\n",
        "                segments.append(segment)\n",
        "        else:\n",
        "            if language == \"hindi\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "            elif language == \"spanish\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
        "            elif language == \"french\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "            elif language == \"german\":\n",
        "                model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "            else:\n",
        "                print(f\"Language '{language}' not supported.\")\n",
        "                return None\n",
        "\n",
        "            tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "            translation_model = MarianMTModel.from_pretrained(model_name)\n",
        "            segments = []\n",
        "            print(f\"Translating to {language}...\")\n",
        "            for segment in result[\"segments\"]:\n",
        "                inputs = tokenizer(segment[\"text\"], return_tensors=\"pt\", padding=True)\n",
        "                translated = translation_model.generate(**inputs)\n",
        "                translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "                segment[\"text\"] = translated_text\n",
        "                segments.append(segment)\n",
        "\n",
        "        srt_path = f\"/content/subtitles_{language}.srt\"\n",
        "        create_srt(segments, srt_path)\n",
        "        return srt_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing video: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    print(\"Choose the source of the video:\")\n",
        "    print(\"1. YouTube\")\n",
        "    print(\"2. Local Drive Path (e.g., /content/video.mp4)\")\n",
        "    choice = input(\"Enter your choice (1 or 2): \").strip()\n",
        "\n",
        "    if os.path.exists(video_path):\n",
        "        os.remove(video_path)  # Clean up previous file if it’s the default path\n",
        "\n",
        "    if choice == \"1\":\n",
        "        youtube_link = input(\"Enter the YouTube video URL: \").strip()\n",
        "        if not youtube_link:\n",
        "            print(\"Error: YouTube URL cannot be empty.\")\n",
        "            return\n",
        "        success = download_youtube_video(youtube_link, video_path)\n",
        "        if not success:\n",
        "            print(\"Failed to download YouTube video. Review the error above for next steps.\")\n",
        "            return\n",
        "        final_video_path = video_path  # Use the downloaded file\n",
        "    elif choice == \"2\":\n",
        "        drive_path = input(\"Enter the local drive path (e.g., /content/M4 Macbook Air Review_ Too Easy!.mkv): \").strip()\n",
        "        if not drive_path:\n",
        "            print(\"Error: Drive path cannot be empty.\")\n",
        "            return\n",
        "        if not os.path.exists(drive_path):\n",
        "            print(f\"Error: File not found at {drive_path}. Please upload the file to Colab first.\")\n",
        "            print(\"To upload: Use the Files tab on the left, or run 'from google.colab import files; files.upload()'.\")\n",
        "            return\n",
        "        final_video_path = drive_path  # Use the provided path directly\n",
        "    else:\n",
        "        print(\"Invalid choice.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nChoose the language for subtitles:\")\n",
        "    print(\"1. English\")\n",
        "    print(\"2. Hindi\")\n",
        "    print(\"3. Spanish\")\n",
        "    print(\"4. French\")\n",
        "    print(\"5. German\")\n",
        "    print(\"6. Telugu\")\n",
        "    language_choice = input(\"Enter your choice (1, 2, 3, 4, 5, or 6): \").strip()\n",
        "\n",
        "    language_map = {\n",
        "        \"1\": \"english\",\n",
        "        \"2\": \"hindi\",\n",
        "        \"3\": \"spanish\",\n",
        "        \"4\": \"french\",\n",
        "        \"5\": \"german\",\n",
        "        \"6\": \"telugu\"\n",
        "    }\n",
        "\n",
        "    if language_choice not in language_map:\n",
        "        print(\"Invalid choice.\")\n",
        "        return\n",
        "\n",
        "    language = language_map[language_choice]\n",
        "    print(f\"\\nStarting video processing for {language} subtitles...\")\n",
        "    srt_path = process_video(final_video_path, language)\n",
        "\n",
        "    if srt_path:\n",
        "        print(f\"\\nSample of {language} subtitles:\")\n",
        "        with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            print(f.read(500))\n",
        "        files.download(srt_path)\n",
        "    else:\n",
        "        print(\"Video failed to process. Please try again.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9_JNA_4OhA_G",
        "outputId": "1f43f17b-8228-4cf9-e88f-d4f346cbd862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3ebaf49478ae4ffb9c41ed804acb49ce",
            "a43ea4f5dd9f429088cd00c160f92333",
            "4c85603f19254afdb06edbfe0a217b97",
            "55d52a8b87c14334959c0278b38838fb",
            "0dd086702af54f09880e724ec215d45b",
            "140b57b1f555447eaf4bb5dcd0dfb530",
            "55c19f2c52da4f4096a3c001799ff6e3",
            "fb17630ea46046ae8e0f60f786331dd2"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-nvrtc-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose the source of the video:\n",
            "1. YouTube\n",
            "2. Local Drive Path (e.g., /content/video.mp4)\n",
            "If the video requires sign-in (e.g., age-restricted), upload a cookies file (optional).\n",
            "Guide: https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a5d1483-3b72-430f-9a61-bbe700d41e1f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a5d1483-3b72-430f-9a61-bbe700d41e1f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving cookies.txt to cookies.txt\n",
            "Cookies uploaded successfully from cookies.txt.\n",
            "Downloaded video to /content/video.mp4\n",
            "Confirmed: /content/video.mp4 exists after download.\n",
            "\n",
            "Choose the language for subtitles:\n",
            "1. English\n",
            "2. Hindi\n",
            "3. Spanish\n",
            "4. French\n",
            "5. German\n",
            "6. Telugu\n",
            "\n",
            "Starting video processing for telugu subtitles...\n",
            "Transcribing video to English...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ebaf49478ae4ffb9c41ed804acb49ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a43ea4f5dd9f429088cd00c160f92333",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c85603f19254afdb06edbfe0a217b97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55d52a8b87c14334959c0278b38838fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dd086702af54f09880e724ec215d45b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140b57b1f555447eaf4bb5dcd0dfb530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c19f2c52da4f4096a3c001799ff6e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translating to Telugu using NLLB-200 Distilled...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb17630ea46046ae8e0f60f786331dd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subtitles saved to /content/subtitles_telugu.srt\n",
            "\n",
            "Sample of telugu subtitles:\n",
            "1\n",
            "00:00:0,000 --> 00:00:5,600\n",
            "ఇది 200,000 డాలర్ల హోండా సివిక్, జపాన్ యొక్క ప్రముఖ ట్యూనింగ్ కంపెనీలచే నిర్మించబడింది,\n",
            "\n",
            "2\n",
            "00:00:5,600 --> 00:00:7,440\n",
            "స్పూన్ మరియు లెజెండ్స్ నిర్మించారు.\n",
            "\n",
            "3\n",
            "00:00:7,440 --> 00:00:10,720\n",
            "కానీ ఎలా మీరు ఒక హోండా సివిక్ కోసం 200 వేల ఖర్చు?\n",
            "\n",
            "4\n",
            "00:00:12,400 --> 00:00:16,000\n",
            "స్పూన్ స్పోర్ట్స్ ఈ చిన్న పసుపు కారును నిర్మించిన రేసింగ్ షాప్.\n",
            "\n",
            "5\n",
            "00:00:16,000 --> 00:00:19,600\n",
            "ఇది ఒక కల మరియు ఒక చిన్న టోక్యో గారేజ్ తో ఒక వ్యక్తి ప్రారంభించారు.\n",
            "\n",
            "6\n",
            "00:00:19,600 --> 00:00:23,760\n",
            "స్\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b88057d-7726-478c-8672-c80cd9e07deb\", \"subtitles_telugu.srt\", 51385)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned up: Removed /content/video.mp4\n"
          ]
        }
      ]
    }
  ]
}